{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "from pprint import pprint\n",
    "import random\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для получения данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxy = {\n",
    "    'http': 'http://46.47.197.210:3128',\n",
    "    'http': 'http://62.33.207.201:80'\n",
    "}\n",
    "\n",
    "def get_api_data(url, params = '', headers ='', proxy = ''): \n",
    "    r = requests.get(url, params, headers=headers, proxies=proxy)\n",
    "    return r.json()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для случайного выбора юзер-агента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_user_agent(user_agents):\n",
    "    user_agent = user_agents[random.randrange(len(user_agents))]\n",
    "    headers = {'user-agent': user_agent}\n",
    "    return headers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтение данных юзерагетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\Lenovo\\Desktop\\diplom\\desktop_user_agent.txt', 'r', encoding='utf-8') as fp:\n",
    "    user_agents = [line.strip() for line in fp.read().split('\\n')]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для получения данных о вакансиях за день"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vac_ids(date):\n",
    "    url = r'https://api.hh.ru/vacancies'\n",
    "    all_vac = []\n",
    "    par = {'text': 'аналитик', 'area': 113, 'search_field': 'name', 'date_from': str(date), 'date_to': str(date)}\n",
    "    data = get_api_data(url, params=par, headers=choose_user_agent(user_agents))\n",
    "    pages = data['pages']\n",
    "    for page in range(pages):\n",
    "        par = {'text': 'аналитик', 'area': 113, 'search_field': 'name', 'date_from': str(date), 'date_to': str(date), 'page': page}\n",
    "        data = get_api_data(url, params=par, headers=choose_user_agent(user_agents))\n",
    "        all_vac = all_vac + data['items']\n",
    "    vac_ids = []\n",
    "    for one_vac in all_vac:\n",
    "        vac_ids.append(one_vac['id'])\n",
    "    vac_ids.sort()\n",
    "    return vac_ids"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка нет ли капчи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "url = f'https://api.hh.ru/vacancies/42018113'\n",
    "vac_descr = get_api_data(url, headers=choose_user_agent(user_agents))\n",
    "area = vac_descr['area']['name']\n",
    "description = re.sub(r'\\<[^>]*\\>', '', vac_descr['description'])\n",
    "employment = vac_descr['employment']['name']\n",
    "experience = vac_descr['experience']['name']\n",
    "id = vac_descr['id']\n",
    "key_skills = vac_descr['key_skills']\n",
    "if len(vac_descr['key_skills']) > 0:\n",
    "    # if len(vac_descr['key_skills'][0]) > 0:\n",
    "    skills = []\n",
    "    for skill in vac_descr['key_skills']:\n",
    "        skills.append(skill['name'])\n",
    "    key_skills = skills\n",
    "name = vac_descr['name']\n",
    "publication_date = vac_descr['published_at'][0:10]\n",
    "salary = vac_descr['salary']\n",
    "schedule = vac_descr['schedule']\n",
    "specializations = vac_descr['specializations']\n",
    "if len(vac_descr['professional_roles']) > 0:\n",
    "    prof_roles = []\n",
    "    for role in vac_descr['professional_roles']:\n",
    "        prof_roles.append(role['name'])\n",
    "    proffesional_roles = prof_roles\n",
    "employer = vac_descr['employer']['name']\n",
    "print(salary)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получение нужных данных о вакансиях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vac_data(vac_ids):\n",
    "    vac_info = []\n",
    "    for one_vac in vac_ids:\n",
    "        url = f'https://api.hh.ru/vacancies/{one_vac}'\n",
    "        vac_descr = get_api_data(url, headers=choose_user_agent(user_agents))\n",
    "        #print(vac_descr)\n",
    "        try:\n",
    "            area = vac_descr['area']['name']\n",
    "            description = re.sub(r'\\<[^>]*\\>', '', vac_descr['description'])\n",
    "            employment = vac_descr['employment']['name']\n",
    "            experience = vac_descr['experience']['name']\n",
    "            id = vac_descr['id']\n",
    "            key_skills = vac_descr['key_skills']\n",
    "            if len(vac_descr['key_skills']) > 0:\n",
    "                skills = []\n",
    "                for skill in vac_descr['key_skills']:\n",
    "                    skills.append(skill['name'])\n",
    "                key_skills = skills\n",
    "            name = vac_descr['name']\n",
    "            publication_date = vac_descr['published_at'][0:10]\n",
    "            salary = vac_descr['salary']\n",
    "            schedule = vac_descr['schedule']['name']\n",
    "            specializations = vac_descr['specializations']\n",
    "            if len(vac_descr['professional_roles']) > 0:\n",
    "                prof_roles = []\n",
    "                for role in vac_descr['professional_roles']:\n",
    "                    prof_roles.append(role['name'])\n",
    "                proffesional_roles = prof_roles\n",
    "            employer = vac_descr['employer']['name']\n",
    "        except:\n",
    "            print(one_vac, 'ERRROR')\n",
    "            continue\n",
    "        vac_info.append({\n",
    "            'area': area,\n",
    "            'description': description,\n",
    "            'employment': employment,\n",
    "            'experience': experience,\n",
    "            'id': id,\n",
    "            'key_skills': key_skills,\n",
    "            'name': name,\n",
    "            'publication_date': publication_date,\n",
    "            'salary': salary,\n",
    "            'schedule': schedule,\n",
    "            'specializations': specializations,\n",
    "            'proffesional_roles': proffesional_roles,\n",
    "            'employer': employer,\n",
    "            'source': 'hh.ru'\n",
    "        })\n",
    "    return vac_info\n",
    "    \n",
    "    #time.sleep(0.1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для дописывания полученные данных за день в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_data_to_file(vac_info, path):\n",
    "    with open(path + '.json', 'r', encoding='utf-8') as fp:\n",
    "        all_vacs = json.load(fp)\n",
    "    all_vacs = all_vacs + vac_info\n",
    "    with open(path + '.json', 'w', encoding='utf-8') as fp:\n",
    "        json.dump(all_vacs, fp, ensure_ascii=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция, чтобы сохранить из json в excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_json_to_excel(path):\n",
    "    with open(path + '.json', 'r', encoding='utf-8') as fp:\n",
    "        to_excel = json.load(fp)\n",
    "    df = pd.DataFrame(to_excel)\n",
    "    df.to_excel(path + '.xlsx')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для добавления навыков в словарь и сохранения в файл (тут собираются уникальные значаения, этот в итоге не нужно)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_skills_to_dict(vac_info, save, path):\n",
    "    with open(path + '.json', 'r', encoding='utf-8') as fp:\n",
    "        skills_dict = json.load(fp)\n",
    "    for i, vac in enumerate(vac_info):\n",
    "        if len(vac['key_skills']) > 0:\n",
    "            for skill in vac['key_skills']:\n",
    "                if skill.lower() not in skills_dict:\n",
    "                    skills_dict.append(skill.lower())\n",
    "    skills_dict.sort()\n",
    "    if save == True:\n",
    "        with open(path + '.json', 'w', encoding='utf-8') as fp:\n",
    "            json.dump(skills_dict, fp, ensure_ascii=False)\n",
    "    return skills_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = get_vac_ids(datetime.date.today() - datetime.timedelta(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "vac_info = get_vac_data(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'area': 'Ульяновск', 'description': 'Привет, мы — MediaSoft.team! Мы разрабатываем сложные веб-системы, бэкенды, мобильные приложения и highload-проекты для бизнеса с 2014 года. У нас в команде 250+ разработчиков по направлениям backend, frontend, mobile, qa и аналитика. Наши офисы находятся в Ульяновске, Санкт-Петербурге, Самаре, Москве и Ростове-на-дону (FIRECODE). У нас точно хватит задач, которые покажутся тебе интересными. А в коллективе точно найдутся эксперты, которые знают больше. Мы предоставим тебе возможность развиваться в той области, которая тебе нравится. Мы уверены, что ты умеешь:  собирать и формулировать бизнес-требования; выявлять функциональные и нефункциональные требования из бизнес-требований; подготавливать техническую документацию (ГОСТы и стандарты, UML-диаграммы, семейство IDEF, BPMN и другие подходы).  Здорово, если ты знаешь SQL, СУБД, REST/SOAP, основы ООП и любого языка программирования. И еще лучше, если ты можешь и хочешь участвовать в выстраивании процессов в команде, знаешь о методологиях и готов к менторству. Само собой, у нас белая зарплата, есть больничные и отпуска, мощная техника на рабочем месте с необходимыми характеристиками. В общем, все как положено. От нас:   Аккредитованная it-компания.   Гибкий график — учитываем режим сов, жаворонков, интровертов и социофобов.   Пересмотр зарплаты несколько раз в год.   Мерч — одеваем с ног до головы в корпоративную одежду и дарим подарки детям сотрудников к Новому году.   Комфортная рабочая среда:     Грамотно руководим: наши руководители прошли путь в компании от разработчиков до управленцев — они знают, как построить эффективные и удобные рабочие процессы.   Обучаем команду: проводим лекции и мастер-классы на собственной образовательной площадке — Академия разработки MediaSoft; поддерживаем библиотеку с технической литературой.   Любим хорошо отдохнуть: громко шумим два раза в год на наших корпоративах и регулярно собираемся вместе в офисе, на турбазе или в баре.   Открыты к идеям, предложениям и творческим порывам.   Мы рады тем, кто разделяет наши ценности и хочет стать частью команды.Давайте работать вместе!', 'employment': 'Полная занятость', 'experience': 'От 1 года до 3 лет', 'id': '40382223', 'key_skills': ['UML', 'BPMN', 'Системный анализ', 'Работа с требованиями', 'SQL', 'REST', 'SOAP'], 'name': 'Системный аналитик', 'publication_date': '2023-03-11', 'salary': {'from': 80000, 'to': 160000, 'currency': 'RUR', 'gross': False}, 'schedule': 'Гибкий график', 'specializations': [], 'proffesional_roles': ['Аналитик'], 'employer': 'МедиаСофт', 'source': 'hh.ru'}\n",
      "447\n"
     ]
    }
   ],
   "source": [
    "print(vac_info[0])\n",
    "print(len(vac_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\Lenovo\\Desktop\\diplom\\hh_data'\n",
    "add_data_to_file(vac_info, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = r'C:\\Users\\Lenovo\\Desktop\\diplom\\hh_data'\n",
    "# from_json_to_excel(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = r'C:\\Users\\Lenovo\\Desktop\\diplom\\skills_dict_orig'\n",
    "#skills_dict = add_skills_to_dict(vac_info, True, path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f8cf99212f81ad0c4765861267244807ee1c18364846cdce387b28994a977ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
