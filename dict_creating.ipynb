{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import regex as re\n",
    "import tools as t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получение данных о скилах во всех вакансиях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105375\n"
     ]
    }
   ],
   "source": [
    "full = pd.read_json('deduplicated.json')['key_skills']\n",
    "skills = []\n",
    "for element in full:\n",
    "    if len(element) > 0:\n",
    "        skills = skills + element\n",
    "print(len(skills))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Навыки, которые не нужно разделять"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_to_split = ['a/b', 'ci/cd', 'pl/sql', 'pl/pg', 'tcp/ip', 'ui/ux', 'ux/ui', 'а/б', 'а/в', 'в/из']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделение перечислений на отдельные навыки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills = t.split_skills(skills, not_to_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.DataFrame(skills)\n",
    "dff['orig'] = dff[0]\n",
    "dff = dff.drop(columns = 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаление нерелевантных символов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['clean'] = dff['orig'].apply(lambda x: t.clean_text(x, not_to_split))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Токенизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dff_1c['tokenize'] = dff_1c['clean'].apply(lambda x: word_tokenize(x, language='russian'))\n",
    "dff['tokenize'] = dff['clean'].apply(lambda x: word_tokenize(x, language='russian'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dff_1c['lemmatize'] = dff_1c['tokenize'].apply(lambda x: t.lemmatization(x))\n",
    "dff['lemmatize'] = dff['tokenize'].apply(lambda x: t.lemmatization(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачивание стоп-слов для русского языка и добавление новых стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "sw_to_add = ['хорошее', 'знание', 'знать', 'опыт', 'работы', 'организация', 'работать', 'ms', 'условия', 'умение', 'навык']\n",
    "sw_to_add = t.lemmatization(sw_to_add)\n",
    "stopwords = stopwords.words('russian')\n",
    "stopwords = stopwords + sw_to_add"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаление стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dff_1c['lemmatize'] = dff_1c['lemmatize'].apply(lambda x: t.remove_stop_words(x, stopwords))\n",
    "dff['lemmatize'] = dff['lemmatize'].apply(lambda x: t.remove_stop_words(x, stopwords))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Составление n-грамм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dff_1c['bigrams'] = dff_1c['lemmatize'].apply(lambda x: list(ngrams(x, 2)))\n",
    "dff['bigrams'] = dff['lemmatize'].apply(lambda x: list(ngrams(x, 2)))\n",
    "\n",
    "#dff_1c['trigrams'] = dff_1c['lemmatize'].apply(lambda x: list(ngrams(x, 3)))\n",
    "dff['trigrams'] = dff['lemmatize'].apply(lambda x: list(ngrams(x, 3)))\n",
    "\n",
    "#dff_1c['fourgrams'] = dff_1c['lemmatize'].apply(lambda x: list(ngrams(x, 4)))\n",
    "dff['fourgrams'] = dff['lemmatize'].apply(lambda x: list(ngrams(x, 4)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получение частоты n-грамм, для которых частота >=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "#most_common_1c = t.most_frequent_ngrams(dff_1c['lemmatize'], 50)\n",
    "most_common = t.most_frequent_ngrams(dff['lemmatize'], 1)\n",
    "\n",
    "#most_common_bigrams_1c = t.most_frequent_ngrams(dff_1c['bigrams'], 50)\n",
    "most_common_bigrams = t.most_frequent_ngrams(dff['bigrams'], 1)\n",
    "\n",
    "#most_common_trigrams_1c = t.most_frequent_ngrams(dff_1c['trigrams'], 50)\n",
    "most_common_trigrams = t.most_frequent_ngrams(dff['trigrams'], 1)\n",
    "\n",
    "#most_common_fourgrams_1c = t.most_frequent_ngrams(dff_1c['fourgrams'], 50)\n",
    "most_common_fourgrams = t.most_frequent_ngrams(dff['fourgrams'], 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохранение полученных n-грамм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ngrams_1c = pd.concat([pd.DataFrame({'unigrams': most_common_1c}), pd.DataFrame({'bigrams': most_common_bigrams_1c}), pd.DataFrame({'trigrams': most_common_trigrams_1c}), pd.DataFrame({'fourgrams': most_common_fourgrams_1c})], axis = 1)\n",
    "df_ngrams = pd.concat([pd.DataFrame({'unigrams': most_common}), pd.DataFrame({'bigrams': most_common_bigrams}), pd.DataFrame({'trigrams': most_common_trigrams}), pd.DataFrame({'fourgrams': most_common_fourgrams})], axis = 1)\n",
    "\n",
    "#df_ngrams_1c.to_excel('ngrams_1c.xlsx')\n",
    "df_ngrams.to_excel('ngrams.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_skill_amount(most_common):\n",
    "    ngram = []\n",
    "    ngram_amount = []\n",
    "    for one in most_common:\n",
    "        ngram.append(str(one[0]))\n",
    "        ngram_amount.append(one[1])\n",
    "    return ngram, ngram_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni, uni_amount = split_skill_amount(most_common)\n",
    "bi, bi_amount = split_skill_amount(most_common_bigrams)\n",
    "tri, tri_amount = split_skill_amount(most_common_trigrams)\n",
    "four, four_amount = split_skill_amount(most_common_fourgrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams = pd.DataFrame({'name': uni, 'amount': uni_amount})\n",
    "bigrams = pd.DataFrame({'name': bi, 'amount': bi_amount})\n",
    "trigrams = pd.DataFrame({'name': tri, 'amount': tri_amount})\n",
    "fourgrams = pd.DataFrame({'name': four, 'amount': four_amount})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "считать количество во всех n+1 граммах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_6624\\258165321.py:2: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  if fourgrams['name'].str.contains(one).any() == True:\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_6624\\258165321.py:4: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  trigrams['amount'][ind] = trigrams['amount'][ind] - fourgrams[fourgrams['name'].str.contains(one)]['amount'].sum()\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_6624\\258165321.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  trigrams['amount'][ind] = trigrams['amount'][ind] - fourgrams[fourgrams['name'].str.contains(one)]['amount'].sum()\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_6624\\258165321.py:13: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  if trigrams['name'].str.contains(one).any() == True:\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_6624\\258165321.py:15: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  bigrams['amount'][ind] = bigrams['amount'][ind] - (trigrams[trigrams['name'].str.contains(one)]['amount'].sum() +\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_6624\\258165321.py:16: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  fourgrams[fourgrams['name'].str.contains(one)]['amount'].sum())\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_6624\\258165321.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bigrams['amount'][ind] = bigrams['amount'][ind] - (trigrams[trigrams['name'].str.contains(one)]['amount'].sum() +\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "multiple repeat at position 12",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [584], line 13\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[39m#if trigrams[trigrams['name'] == one]['amount'].item() <= (fourgrams[fourgrams['name'].str.contains(one)]['amount'].sum()):\u001b[39;00m\n\u001b[0;32m      9\u001b[0m             \u001b[39m#trigrams = trigrams[trigrams.name != one]\u001b[39;00m\n\u001b[0;32m     10\u001b[0m             \u001b[39m#pass\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39mfor\u001b[39;00m one \u001b[39min\u001b[39;00m bigrams[\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m---> 13\u001b[0m     \u001b[39mif\u001b[39;00m trigrams[\u001b[39m'\u001b[39;49m\u001b[39mname\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mstr\u001b[39m.\u001b[39;49mcontains(one)\u001b[39m.\u001b[39many() \u001b[39m==\u001b[39m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m         ind \u001b[39m=\u001b[39m bigrams\u001b[39m.\u001b[39mindex[bigrams[\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m one]\u001b[39m.\u001b[39mtolist()[\u001b[39m0\u001b[39m]\n\u001b[0;32m     15\u001b[0m         bigrams[\u001b[39m'\u001b[39m\u001b[39mamount\u001b[39m\u001b[39m'\u001b[39m][ind] \u001b[39m=\u001b[39m bigrams[\u001b[39m'\u001b[39m\u001b[39mamount\u001b[39m\u001b[39m'\u001b[39m][ind] \u001b[39m-\u001b[39m (trigrams[trigrams[\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mcontains(one)][\u001b[39m'\u001b[39m\u001b[39mamount\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39msum() \u001b[39m+\u001b[39m \n\u001b[0;32m     16\u001b[0m                                                            fourgrams[fourgrams[\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mcontains(one)][\u001b[39m'\u001b[39m\u001b[39mamount\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39msum())\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:129\u001b[0m, in \u001b[0;36mforbid_nonstring_types.<locals>._forbid_nonstring_types.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    124\u001b[0m     msg \u001b[39m=\u001b[39m (\n\u001b[0;32m    125\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot use .str.\u001b[39m\u001b[39m{\u001b[39;00mfunc_name\u001b[39m}\u001b[39;00m\u001b[39m with values of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    126\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minferred dtype \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_dtype\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    127\u001b[0m     )\n\u001b[0;32m    128\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 129\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:1252\u001b[0m, in \u001b[0;36mStringMethods.contains\u001b[1;34m(self, pat, case, flags, na, regex)\u001b[0m\n\u001b[0;32m   1127\u001b[0m \u001b[39m@forbid_nonstring_types\u001b[39m([\u001b[39m\"\u001b[39m\u001b[39mbytes\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m   1128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcontains\u001b[39m(\u001b[39mself\u001b[39m, pat, case\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, flags\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, na\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, regex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m   1129\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1130\u001b[0m \u001b[39m    Test if pattern or regex is contained within a string of a Series or Index.\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1250\u001b[0m \u001b[39m    dtype: bool\u001b[39;00m\n\u001b[0;32m   1251\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1252\u001b[0m     \u001b[39mif\u001b[39;00m regex \u001b[39mand\u001b[39;00m re\u001b[39m.\u001b[39;49mcompile(pat)\u001b[39m.\u001b[39mgroups:\n\u001b[0;32m   1253\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1254\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThis pattern is interpreted as a regular expression, and has \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1255\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mmatch groups. To actually get the groups, use str.extract.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1256\u001b[0m             \u001b[39mUserWarning\u001b[39;00m,\n\u001b[0;32m   1257\u001b[0m             stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   1258\u001b[0m         )\n\u001b[0;32m   1260\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data\u001b[39m.\u001b[39marray\u001b[39m.\u001b[39m_str_contains(pat, case, flags, na, regex)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\re.py:252\u001b[0m, in \u001b[0;36mcompile\u001b[1;34m(pattern, flags)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompile\u001b[39m(pattern, flags\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[0;32m    251\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mCompile a regular expression pattern, returning a Pattern object.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 252\u001b[0m     \u001b[39mreturn\u001b[39;00m _compile(pattern, flags)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\re.py:304\u001b[0m, in \u001b[0;36m_compile\u001b[1;34m(pattern, flags)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m sre_compile\u001b[39m.\u001b[39misstring(pattern):\n\u001b[0;32m    303\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mfirst argument must be string or compiled pattern\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 304\u001b[0m p \u001b[39m=\u001b[39m sre_compile\u001b[39m.\u001b[39;49mcompile(pattern, flags)\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (flags \u001b[39m&\u001b[39m DEBUG):\n\u001b[0;32m    306\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(_cache) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m _MAXCACHE:\n\u001b[0;32m    307\u001b[0m         \u001b[39m# Drop the oldest item\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\sre_compile.py:764\u001b[0m, in \u001b[0;36mcompile\u001b[1;34m(p, flags)\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[39mif\u001b[39;00m isstring(p):\n\u001b[0;32m    763\u001b[0m     pattern \u001b[39m=\u001b[39m p\n\u001b[1;32m--> 764\u001b[0m     p \u001b[39m=\u001b[39m sre_parse\u001b[39m.\u001b[39;49mparse(p, flags)\n\u001b[0;32m    765\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    766\u001b[0m     pattern \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\sre_parse.py:948\u001b[0m, in \u001b[0;36mparse\u001b[1;34m(str, flags, state)\u001b[0m\n\u001b[0;32m    945\u001b[0m state\u001b[39m.\u001b[39mstr \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m\n\u001b[0;32m    947\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 948\u001b[0m     p \u001b[39m=\u001b[39m _parse_sub(source, state, flags \u001b[39m&\u001b[39;49m SRE_FLAG_VERBOSE, \u001b[39m0\u001b[39;49m)\n\u001b[0;32m    949\u001b[0m \u001b[39mexcept\u001b[39;00m Verbose:\n\u001b[0;32m    950\u001b[0m     \u001b[39m# the VERBOSE flag was switched on inside the pattern.  to be\u001b[39;00m\n\u001b[0;32m    951\u001b[0m     \u001b[39m# on the safe side, we'll parse the whole thing again...\u001b[39;00m\n\u001b[0;32m    952\u001b[0m     state \u001b[39m=\u001b[39m State()\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\sre_parse.py:443\u001b[0m, in \u001b[0;36m_parse_sub\u001b[1;34m(source, state, verbose, nested)\u001b[0m\n\u001b[0;32m    441\u001b[0m start \u001b[39m=\u001b[39m source\u001b[39m.\u001b[39mtell()\n\u001b[0;32m    442\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 443\u001b[0m     itemsappend(_parse(source, state, verbose, nested \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[0;32m    444\u001b[0m                        \u001b[39mnot\u001b[39;49;00m nested \u001b[39mand\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m items))\n\u001b[0;32m    445\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m sourcematch(\u001b[39m\"\u001b[39m\u001b[39m|\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    446\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\sre_parse.py:834\u001b[0m, in \u001b[0;36m_parse\u001b[1;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[0;32m    831\u001b[0m         \u001b[39mraise\u001b[39;00m source\u001b[39m.\u001b[39merror(err\u001b[39m.\u001b[39mmsg, \u001b[39mlen\u001b[39m(name) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    832\u001b[0m sub_verbose \u001b[39m=\u001b[39m ((verbose \u001b[39mor\u001b[39;00m (add_flags \u001b[39m&\u001b[39m SRE_FLAG_VERBOSE)) \u001b[39mand\u001b[39;00m\n\u001b[0;32m    833\u001b[0m                \u001b[39mnot\u001b[39;00m (del_flags \u001b[39m&\u001b[39m SRE_FLAG_VERBOSE))\n\u001b[1;32m--> 834\u001b[0m p \u001b[39m=\u001b[39m _parse_sub(source, state, sub_verbose, nested \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[0;32m    835\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m source\u001b[39m.\u001b[39mmatch(\u001b[39m\"\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    836\u001b[0m     \u001b[39mraise\u001b[39;00m source\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mmissing ), unterminated subpattern\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    837\u001b[0m                        source\u001b[39m.\u001b[39mtell() \u001b[39m-\u001b[39m start)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\sre_parse.py:443\u001b[0m, in \u001b[0;36m_parse_sub\u001b[1;34m(source, state, verbose, nested)\u001b[0m\n\u001b[0;32m    441\u001b[0m start \u001b[39m=\u001b[39m source\u001b[39m.\u001b[39mtell()\n\u001b[0;32m    442\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 443\u001b[0m     itemsappend(_parse(source, state, verbose, nested \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[0;32m    444\u001b[0m                        \u001b[39mnot\u001b[39;49;00m nested \u001b[39mand\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m items))\n\u001b[0;32m    445\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m sourcematch(\u001b[39m\"\u001b[39m\u001b[39m|\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    446\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\sre_parse.py:671\u001b[0m, in \u001b[0;36m_parse\u001b[1;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[0;32m    668\u001b[0m     \u001b[39mraise\u001b[39;00m source\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mnothing to repeat\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    669\u001b[0m                        source\u001b[39m.\u001b[39mtell() \u001b[39m-\u001b[39m here \u001b[39m+\u001b[39m \u001b[39mlen\u001b[39m(this))\n\u001b[0;32m    670\u001b[0m \u001b[39mif\u001b[39;00m item[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m] \u001b[39min\u001b[39;00m _REPEATCODES:\n\u001b[1;32m--> 671\u001b[0m     \u001b[39mraise\u001b[39;00m source\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mmultiple repeat\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    672\u001b[0m                        source\u001b[39m.\u001b[39mtell() \u001b[39m-\u001b[39m here \u001b[39m+\u001b[39m \u001b[39mlen\u001b[39m(this))\n\u001b[0;32m    673\u001b[0m \u001b[39mif\u001b[39;00m item[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m] \u001b[39mis\u001b[39;00m SUBPATTERN:\n\u001b[0;32m    674\u001b[0m     group, add_flags, del_flags, p \u001b[39m=\u001b[39m item[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m]\n",
      "\u001b[1;31merror\u001b[0m: multiple repeat at position 12"
     ]
    }
   ],
   "source": [
    "for one in trigrams['name']:\n",
    "    if fourgrams['name'].str.contains(one).any() == True:\n",
    "        ind = trigrams.index[trigrams['name'] == one].tolist()[0]\n",
    "        trigrams['amount'][ind] = trigrams['amount'][ind] - fourgrams[fourgrams['name'].str.contains(one)]['amount'].sum()\n",
    "        if trigrams['amount'][ind] < 0:\n",
    "            trigrams = trigrams[trigrams.name != one]\n",
    "\n",
    "        #if trigrams[trigrams['name'] == one]['amount'].item() <= (fourgrams[fourgrams['name'].str.contains(one)]['amount'].sum()):\n",
    "            #trigrams = trigrams[trigrams.name != one]\n",
    "            #pass\n",
    "\n",
    "for one in bigrams['name']:\n",
    "    if trigrams['name'].str.contains(one).any() == True:\n",
    "        ind = bigrams.index[bigrams['name'] == one].tolist()[0]\n",
    "        bigrams['amount'][ind] = bigrams['amount'][ind] - (trigrams[trigrams['name'].str.contains(one)]['amount'].sum() + \n",
    "                                                           fourgrams[fourgrams['name'].str.contains(one)]['amount'].sum())\n",
    "        if bigrams['amount'][ind] < 0:\n",
    "            bigrams = bigrams[bigrams.name != one]\n",
    "        # if bigrams[bigrams['name'] == one]['amount'].item() <= (trigrams[trigrams['name'].str.contains(one)]['amount'].sum() +\n",
    "        #                                                         fourgrams[fourgrams['name'].str.contains(one)]['amount'].sum()):\n",
    "        #     bigrams = bigrams[bigrams.name != one]\n",
    "\n",
    "for one in unigrams['name']:\n",
    "    search = one\n",
    "    if one == 'c++':\n",
    "         one = 'c+'\n",
    "    if bigrams['name'].str.contains(\"'\" + one + \"'\").any() == True:\n",
    "        ind = unigrams.index[unigrams['name'] == search].tolist()[0]\n",
    "        unigrams['amount'][ind] = unigrams['amount'][ind] - (bigrams[bigrams['name'].str.contains(one)]['amount'].sum() + \n",
    "                                                             trigrams[trigrams['name'].str.contains(one)]['amount'].sum() + \n",
    "                                                             fourgrams[fourgrams['name'].str.contains(one)]['amount'].sum())\n",
    "        if unigrams['amount'][ind] < 0:\n",
    "            unigrams = unigrams[unigrams.name != search]\n",
    "\n",
    "        # if unigrams[unigrams['name'] == search]['amount'].item() <= (bigrams[bigrams['name'].str.contains(one)]['amount'].sum() + \n",
    "        #                                                              trigrams[trigrams['name'].str.contains(one)]['amount'].sum() +\n",
    "        #                                                              fourgrams[fourgrams['name'].str.contains(one)]['amount'].sum()):\n",
    "        #     unigrams = unigrams[unigrams.name != search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875 674 183 31\n"
     ]
    }
   ],
   "source": [
    "# print(len(unigrams), len(bigrams), len(trigrams), len(fourgrams))\n",
    "# trigrams = clean_ngrams(n1gramm = trigrams, n2gram = fourgrams)\n",
    "# bigrams = clean_ngrams(n1gramm = bigrams, n2gram = trigrams)\n",
    "# unigrams = clean_ngrams(n1gramm = unigrams, n2gram = bigrams)\n",
    "print(len(unigrams), len(bigrams), len(trigrams), len(fourgrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105649\n"
     ]
    }
   ],
   "source": [
    "skills_count = unigrams.amount.sum() + bigrams.amount.sum() + trigrams.amount.sum() + fourgrams.amount.sum()\n",
    "print(skills_count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаление \"не навыков\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_delete_from_dict = pd.read_csv('words_to_delete_from_dict.csv')['0'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_full = pd.concat([unigrams, bigrams, trigrams, fourgrams], axis = 0, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_full['name'] = ngrams_full['name'].apply(lambda x: None if x in to_delete_from_dict else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_full.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngrams_full = pd.concat([unigrams, bigrams, trigrams, fourgrams], axis = 0, ignore_index = True)\n",
    "ngrams_full.sort_values(by = 'amount', ascending = False, inplace = True, ignore_index = True)\n",
    "ngrams_full['cumperc'] = ngrams_full['amount'].cumsum()/ngrams_full['amount'].sum()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_full = ngrams_full[ngrams_full['cumperc'] < 80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>amount</th>\n",
       "      <th>cumperc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1с</td>\n",
       "      <td>5896</td>\n",
       "      <td>4.318813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sql</td>\n",
       "      <td>5649</td>\n",
       "      <td>8.456698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>('аналитический', 'мышление')</td>\n",
       "      <td>3465</td>\n",
       "      <td>10.994807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bpmn</td>\n",
       "      <td>2405</td>\n",
       "      <td>12.756466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>('бизнес', 'анализ')</td>\n",
       "      <td>2395</td>\n",
       "      <td>14.510801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>кредит</td>\n",
       "      <td>55</td>\n",
       "      <td>79.823321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>('регламентировать', 'учёт')</td>\n",
       "      <td>54</td>\n",
       "      <td>79.862876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>('analytical', 'skills')</td>\n",
       "      <td>54</td>\n",
       "      <td>79.902431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>('математический', 'склад', 'ум')</td>\n",
       "      <td>54</td>\n",
       "      <td>79.941986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>сэд</td>\n",
       "      <td>54</td>\n",
       "      <td>79.981541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>310 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  name  amount    cumperc\n",
       "0                                   1с    5896   4.318813\n",
       "1                                  sql    5649   8.456698\n",
       "2        ('аналитический', 'мышление')    3465  10.994807\n",
       "3                                 bpmn    2405  12.756466\n",
       "4                 ('бизнес', 'анализ')    2395  14.510801\n",
       "..                                 ...     ...        ...\n",
       "305                             кредит      55  79.823321\n",
       "306       ('регламентировать', 'учёт')      54  79.862876\n",
       "307           ('analytical', 'skills')      54  79.902431\n",
       "308  ('математический', 'склад', 'ум')      54  79.941986\n",
       "309                                сэд      54  79.981541\n",
       "\n",
       "[310 rows x 3 columns]"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams_full"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "по-хорошему, стоит перепроверить получившиеся навыки и все равно кое-что убрать вручную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_full.to_excel('dict-pareto_v8.xlsx')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "удаление ',()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_full['name'] = ngrams_full['name'].apply(lambda x: re.sub(\"[\\'(),]\", '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После ручной обработки n-грамм - получаем словарь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_full['name'].to_excel('automatic generated dict.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f8cf99212f81ad0c4765861267244807ee1c18364846cdce387b28994a977ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
