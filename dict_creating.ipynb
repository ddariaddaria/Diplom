{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import tools as t\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получение данных о скилах во всех вакансиях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118525\n"
     ]
    }
   ],
   "source": [
    "full = pd.read_json('deduplicated.json')['key_skills']\n",
    "skills = []\n",
    "for element in full:\n",
    "    if len(element) > 0:\n",
    "        skills = skills + element\n",
    "print(len(skills))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Навыки, которые не нужно разделять"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_to_split = ['a/b', 'ci/cd', 'pl/sql', 'pl/pg', 'tcp/ip', 'ui/ux', 'ux/ui', 'а/б', 'а/в', 'в/из', 'c++']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделение перечислений на отдельные навыки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills = t.split_skills(skills, not_to_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.DataFrame(skills)\n",
    "dff['orig'] = dff[0]\n",
    "dff = dff.drop(columns = 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаление нерелевантных символов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['clean'] = dff['orig'].apply(lambda x: t.clean_text(x, not_to_split))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Токенизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dff_1c['tokenize'] = dff_1c['clean'].apply(lambda x: word_tokenize(x, language='russian'))\n",
    "dff['tokenize'] = dff['clean'].apply(lambda x: word_tokenize(x, language='russian'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dff_1c['lemmatize'] = dff_1c['tokenize'].apply(lambda x: t.lemmatization(x))\n",
    "dff['lemmatize'] = dff['tokenize'].apply(lambda x: t.lemmatization(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачивание стоп-слов для русского языка и добавление новых стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "sw_to_add = ['хорошее', 'знание', 'знать', 'опыт', 'работы', 'организация', 'работать', 'ms', 'условия', 'умение', 'навык']\n",
    "sw_to_add = t.lemmatization(sw_to_add)\n",
    "stopwords = stopwords.words('russian')\n",
    "stopwords = stopwords + sw_to_add"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаление стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dff_1c['lemmatize'] = dff_1c['lemmatize'].apply(lambda x: t.remove_stop_words(x, stopwords))\n",
    "dff['lemmatize'] = dff['lemmatize'].apply(lambda x: t.remove_stop_words(x, stopwords))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Составление n-грамм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dff_1c['bigrams'] = dff_1c['lemmatize'].apply(lambda x: list(ngrams(x, 2)))\n",
    "dff['bigrams'] = dff['lemmatize'].apply(lambda x: list(ngrams(x, 2)))\n",
    "\n",
    "#dff_1c['trigrams'] = dff_1c['lemmatize'].apply(lambda x: list(ngrams(x, 3)))\n",
    "dff['trigrams'] = dff['lemmatize'].apply(lambda x: list(ngrams(x, 3)))\n",
    "\n",
    "#dff_1c['fourgrams'] = dff_1c['lemmatize'].apply(lambda x: list(ngrams(x, 4)))\n",
    "dff['fourgrams'] = dff['lemmatize'].apply(lambda x: list(ngrams(x, 4)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получение частоты n-грамм, для которых частота >=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#most_common_1c = t.most_frequent_ngrams(dff_1c['lemmatize'], 50)\n",
    "most_common = t.most_frequent_ngrams(dff['lemmatize'], 1)\n",
    "\n",
    "#most_common_bigrams_1c = t.most_frequent_ngrams(dff_1c['bigrams'], 50)\n",
    "most_common_bigrams = t.most_frequent_ngrams(dff['bigrams'], 1)\n",
    "\n",
    "#most_common_trigrams_1c = t.most_frequent_ngrams(dff_1c['trigrams'], 50)\n",
    "most_common_trigrams = t.most_frequent_ngrams(dff['trigrams'], 1)\n",
    "\n",
    "#most_common_fourgrams_1c = t.most_frequent_ngrams(dff_1c['fourgrams'], 50)\n",
    "most_common_fourgrams = t.most_frequent_ngrams(dff['fourgrams'], 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохранение полученных n-грамм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ngrams_1c = pd.concat([pd.DataFrame({'unigrams': most_common_1c}), pd.DataFrame({'bigrams': most_common_bigrams_1c}), pd.DataFrame({'trigrams': most_common_trigrams_1c}), pd.DataFrame({'fourgrams': most_common_fourgrams_1c})], axis = 1)\n",
    "df_ngrams = pd.concat([pd.DataFrame({'unigrams': most_common}), pd.DataFrame({'bigrams': most_common_bigrams}), pd.DataFrame({'trigrams': most_common_trigrams}), pd.DataFrame({'fourgrams': most_common_fourgrams})], axis = 1)\n",
    "\n",
    "#df_ngrams_1c.to_excel('ngrams_1c.xlsx')\n",
    "# df_ngrams.to_excel('ngrams.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_skill_amount(most_common):\n",
    "    ngram = []\n",
    "    ngram_amount = []\n",
    "    for one in most_common:\n",
    "        ngram.append(str(one[0]))\n",
    "        ngram_amount.append(one[1])\n",
    "    return ngram, ngram_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni, uni_amount = split_skill_amount(most_common)\n",
    "bi, bi_amount = split_skill_amount(most_common_bigrams)\n",
    "tri, tri_amount = split_skill_amount(most_common_trigrams)\n",
    "four, four_amount = split_skill_amount(most_common_fourgrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams = pd.DataFrame({'name': uni, 'amount': uni_amount})\n",
    "bigrams = pd.DataFrame({'name': bi, 'amount': bi_amount})\n",
    "trigrams = pd.DataFrame({'name': tri, 'amount': tri_amount})\n",
    "fourgrams = pd.DataFrame({'name': four, 'amount': four_amount})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "считать количество во всех n+1 граммах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_2768\\4214716955.py:2: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  if fourgrams['name'].str.contains(one).any() == True:\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_2768\\4214716955.py:4: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  trigrams['amount'][ind] = trigrams['amount'][ind] - fourgrams[fourgrams['name'].str.contains(one)]['amount'].sum()\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_2768\\4214716955.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  trigrams['amount'][ind] = trigrams['amount'][ind] - fourgrams[fourgrams['name'].str.contains(one)]['amount'].sum()\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_2768\\4214716955.py:13: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  if trigrams['name'].str.contains(one).any() == True:\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_2768\\4214716955.py:15: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  bigrams['amount'][ind] = bigrams['amount'][ind] - (trigrams[trigrams['name'].str.contains(one)]['amount'].sum() +\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_2768\\4214716955.py:16: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  fourgrams[fourgrams['name'].str.contains(one)]['amount'].sum())\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_2768\\4214716955.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bigrams['amount'][ind] = bigrams['amount'][ind] - (trigrams[trigrams['name'].str.contains(one)]['amount'].sum() +\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_2768\\4214716955.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unigrams['amount'][ind] = unigrams['amount'][ind] - (bigrams[bigrams['name'].str.contains(one)]['amount'].sum() +\n"
     ]
    }
   ],
   "source": [
    "for one in trigrams['name']:\n",
    "    if fourgrams['name'].str.contains(one).any() == True:\n",
    "        ind = trigrams.index[trigrams['name'] == one].tolist()[0]\n",
    "        trigrams['amount'][ind] = trigrams['amount'][ind] - fourgrams[fourgrams['name'].str.contains(one)]['amount'].sum()\n",
    "        if trigrams['amount'][ind] < 0:\n",
    "            trigrams = trigrams[trigrams.name != one]\n",
    "\n",
    "        #if trigrams[trigrams['name'] == one]['amount'].item() <= (fourgrams[fourgrams['name'].str.contains(one)]['amount'].sum()):\n",
    "            #trigrams = trigrams[trigrams.name != one]\n",
    "            #pass\n",
    "\n",
    "for one in bigrams['name']:\n",
    "    if trigrams['name'].str.contains(one).any() == True:\n",
    "        ind = bigrams.index[bigrams['name'] == one].tolist()[0]\n",
    "        bigrams['amount'][ind] = bigrams['amount'][ind] - (trigrams[trigrams['name'].str.contains(one)]['amount'].sum() + \n",
    "                                                           fourgrams[fourgrams['name'].str.contains(one)]['amount'].sum())\n",
    "        if bigrams['amount'][ind] < 0:\n",
    "            bigrams = bigrams[bigrams.name != one]\n",
    "        # if bigrams[bigrams['name'] == one]['amount'].item() <= (trigrams[trigrams['name'].str.contains(one)]['amount'].sum() +\n",
    "        #                                                         fourgrams[fourgrams['name'].str.contains(one)]['amount'].sum()):\n",
    "        #     bigrams = bigrams[bigrams.name != one]\n",
    "\n",
    "for index, one in enumerate(unigrams['name']):\n",
    "    search = one\n",
    "    # if one == 'c++':\n",
    "    #      one = 'c+'\n",
    "    try:\n",
    "        bigrams['name'].str.contains(\"'\" + one + \"'\").any()\n",
    "    except:\n",
    "        print(one, index)\n",
    "    if bigrams['name'].str.contains(\"'\" + one + \"'\").any() == True:\n",
    "        ind = unigrams.index[unigrams['name'] == search].tolist()[0]\n",
    "        unigrams['amount'][ind] = unigrams['amount'][ind] - (bigrams[bigrams['name'].str.contains(one)]['amount'].sum() + \n",
    "                                                             trigrams[trigrams['name'].str.contains(one)]['amount'].sum() + \n",
    "                                                             fourgrams[fourgrams['name'].str.contains(one)]['amount'].sum())\n",
    "        if unigrams['amount'][ind] < 0:\n",
    "            unigrams = unigrams[unigrams.name != search]\n",
    "\n",
    "        # if unigrams[unigrams['name'] == search]['amount'].item() <= (bigrams[bigrams['name'].str.contains(one)]['amount'].sum() + \n",
    "        #                                                              trigrams[trigrams['name'].str.contains(one)]['amount'].sum() +\n",
    "        #                                                              fourgrams[fourgrams['name'].str.contains(one)]['amount'].sum()):\n",
    "        #     unigrams = unigrams[unigrams.name != search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2882 3734 1299 412\n"
     ]
    }
   ],
   "source": [
    "# print(len(unigrams), len(bigrams), len(trigrams), len(fourgrams))\n",
    "# trigrams = clean_ngrams(n1gramm = trigrams, n2gram = fourgrams)\n",
    "# bigrams = clean_ngrams(n1gramm = bigrams, n2gram = trigrams)\n",
    "# unigrams = clean_ngrams(n1gramm = unigrams, n2gram = bigrams)\n",
    "print(len(unigrams), len(bigrams), len(trigrams), len(fourgrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118547\n"
     ]
    }
   ],
   "source": [
    "skills_count = unigrams.amount.sum() + bigrams.amount.sum() + trigrams.amount.sum() + fourgrams.amount.sum()\n",
    "print(skills_count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаление \"не навыков\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_delete_from_dict = pd.read_csv('words_to_delete_from_dict.csv')['0'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_full = pd.concat([unigrams, bigrams, trigrams, fourgrams], axis = 0, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_full['name'] = ngrams_full['name'].apply(lambda x: None if x in to_delete_from_dict else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_full.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngrams_full = pd.concat([unigrams, bigrams, trigrams, fourgrams], axis = 0, ignore_index = True)\n",
    "ngrams_full.sort_values(by = 'amount', ascending = False, inplace = True, ignore_index = True)\n",
    "ngrams_full['cumperc'] = ngrams_full['amount'].cumsum()/ngrams_full['amount'].sum()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_full = ngrams_full[ngrams_full['cumperc'] < 80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>amount</th>\n",
       "      <th>cumperc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sql</td>\n",
       "      <td>6656</td>\n",
       "      <td>5.921392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>('аналитический', 'мышление')</td>\n",
       "      <td>3939</td>\n",
       "      <td>9.425653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bpmn</td>\n",
       "      <td>3087</td>\n",
       "      <td>12.171948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>('бизнес', 'анализ')</td>\n",
       "      <td>2935</td>\n",
       "      <td>14.783019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>excel</td>\n",
       "      <td>2425</td>\n",
       "      <td>16.940377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>('моделирование', 'процесс')</td>\n",
       "      <td>74</td>\n",
       "      <td>79.699482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>моделирование</td>\n",
       "      <td>71</td>\n",
       "      <td>79.762646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>('бизнес', 'планирование')</td>\n",
       "      <td>70</td>\n",
       "      <td>79.824920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>('бизнес', 'процесс')</td>\n",
       "      <td>70</td>\n",
       "      <td>79.887195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>swagger</td>\n",
       "      <td>70</td>\n",
       "      <td>79.949469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              name  amount    cumperc\n",
       "0                              sql    6656   5.921392\n",
       "1    ('аналитический', 'мышление')    3939   9.425653\n",
       "2                             bpmn    3087  12.171948\n",
       "3             ('бизнес', 'анализ')    2935  14.783019\n",
       "4                            excel    2425  16.940377\n",
       "..                             ...     ...        ...\n",
       "211   ('моделирование', 'процесс')      74  79.699482\n",
       "212                  моделирование      71  79.762646\n",
       "213     ('бизнес', 'планирование')      70  79.824920\n",
       "214          ('бизнес', 'процесс')      70  79.887195\n",
       "215                        swagger      70  79.949469\n",
       "\n",
       "[216 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams_full"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "по-хорошему, стоит перепроверить получившиеся навыки и все равно кое-что убрать вручную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_full.to_excel('dict-pareto_v9.xlsx')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "удаление ',()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_full['name'] = ngrams_full['name'].apply(lambda x: re.sub(\"[\\'(),]\", '', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После ручной обработки n-грамм - получаем словарь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_full['name'].to_excel('automatic generated dict.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f8cf99212f81ad0c4765861267244807ee1c18364846cdce387b28994a977ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
