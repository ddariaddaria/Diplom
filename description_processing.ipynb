{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tools as t"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предобработка тектов вакансий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_descr = pd.DataFrame(pd.read_json('deduplicated.json')[['id', 'description', 'key_skills']])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаление нерелевантных символов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_to_split = ['a/b', 'ci/cd', 'pl/sql', 'pl/pg', 'tcp/ip', 'ui/ux', 'ux/ui', 'а/б', 'а/в', 'в/из']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_descr['d_clean'] = df_descr['description'].apply(lambda x: t.clean_text(x, not_to_split))\n",
    "df_descr['ks_clean'] = df_descr['key_skills'].apply(lambda x: t.clean_text(str(x), not_to_split))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Токенизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_descr['d_tokens'] = df_descr['d_clean'].apply(lambda x: word_tokenize(x, language = 'russian'))\n",
    "df_descr['ks_tokens'] = df_descr['ks_clean'].apply(lambda x: word_tokenize(x, language = 'russian'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматизация (23771 текста обрабатывались 55 мин 29 сек)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_descr['d_lemmatized'] = df_descr['d_tokens'].apply(lambda x: t.lemmatization(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_descr['ks_lemmatized'] = df_descr['ks_tokens'].apply(lambda x: t.lemmatization(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_descr['ks_clean'][df_descr['ks_clean'].str.contains('excel') == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачивание стоп-слов для русского языка и добавление новых стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "sw_to_add = ['хорошее', 'знание', 'знать', 'опыт', 'работы', 'организация', 'работать', 'ms', 'условия', 'умение', 'навык']\n",
    "sw_to_add = t.lemmatization(sw_to_add)\n",
    "stopwords = stopwords.words('russian')\n",
    "stopwords = stopwords + sw_to_add"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаление стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_descr['d_wo_sw'] = df_descr['d_lemmatized'].apply(lambda x: t.remove_stop_words(x, stopwords))\n",
    "df_descr['ks_wo_sw'] = df_descr['ks_lemmatized'].apply(lambda x: t.remove_stop_words(x, stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.DataFrame(pd.read_json('deduplicated.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_descr['proffesional_roles'] = df_full['proffesional_roles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_descr.to_json('preprocessed_text.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_descr = pd.read_json('preprocessed_text.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_descr['d_full'] = df_descr['d_wo_sw'].apply(lambda x: ' '.join(x))\n",
    "df_descr['ks_full'] = df_descr['ks_wo_sw'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SKILL COUNT BASED ON DICTIONARY"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем датафрейм из id, полного описания вакансии и key_skills, добавляем столбец с пустыми списками (для полученных навыков) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descr = pd.DataFrame({'id': df_descr['id'], 'd_full': df_descr['d_full'], 'ks_full': df_descr['ks_full']})\n",
    "descr['extracted_skills'] = descr.apply(lambda _: [], axis = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем словарь навыков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = pd.read_excel('automatic generated dict.xlsx')['name'].to_list()\n",
    "skills = dict.fromkeys(df_dict, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для подсчета частоты встечаемости навыков и вытаскивания навыков в отдельное поле"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skills_count(id):\n",
    "    ind = descr.index[descr['id'] == id].tolist()[0]\n",
    "    text = descr['d_full'][ind]\n",
    "    ks = descr['ks_full'][ind]\n",
    "    for skill in skills:\n",
    "        if re.search(skill, ks) != None:\n",
    "            descr['extracted_skills'][ind].append(skill)\n",
    "            skills[skill] += 1\n",
    "        elif re.search(skill, text) != None:\n",
    "            descr['extracted_skills'][ind].append(skill)\n",
    "            skills[skill] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descr['id'].apply(lambda x: skills_count(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сортировка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills = dict(sorted(skills.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохранение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descr.to_json('extracted_skills.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f8cf99212f81ad0c4765861267244807ee1c18364846cdce387b28994a977ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
